{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P300b and MMN Analysis Workflow\n",
    "\n",
    "This notebook contains the workflow for analyzing P300b and MMN difference waves using MNE-Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install mne numpy scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.stats import permutation_cluster_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the epochs\n",
    "epochs = mne.read_epochs('18-2.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate consecutive significant samples\n",
    "def calculate_consecutive_significant(p_values, threshold):\n",
    "    sig_mask = p_values < threshold\n",
    "    consecutive_count = np.zeros_like(sig_mask, dtype=int)\n",
    "    \n",
    "    for ch in range(sig_mask.shape[0]):\n",
    "        count = 0\n",
    "        for t in range(sig_mask.shape[1]):\n",
    "            if sig_mask[ch, t]:\n",
    "                count += 1\n",
    "            else:\n",
    "                count = 0\n",
    "            consecutive_count[ch, t] = count\n",
    "    \n",
    "    return np.max(consecutive_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and plot difference wave\n",
    "def calculate_and_plot_difference_wave(condition1, condition2, electrodes, time_window, title, find_negative=False):\n",
    "    epochs_cond1 = epochs[condition1].copy().pick(electrodes)\n",
    "    epochs_cond2 = epochs[condition2].copy().pick(electrodes)\n",
    "    \n",
    "    evoked_cond1 = epochs_cond1.average()\n",
    "    evoked_cond2 = epochs_cond2.average()\n",
    "    \n",
    "    diff_data = evoked_cond1.data - evoked_cond2.data\n",
    "    diff_wave = mne.EvokedArray(diff_data, evoked_cond1.info, tmin=evoked_cond1.times[0])\n",
    "    \n",
    "    time_mask = (diff_wave.times >= time_window[0]) & (diff_wave.times <= time_window[1])\n",
    "    data_window = diff_wave.data[:, time_mask]\n",
    "    mean_data_window = data_window.mean(axis=0)\n",
    "    \n",
    "    if find_negative:\n",
    "        peak_amplitude = np.min(mean_data_window)\n",
    "        peak_latency = diff_wave.times[time_mask][np.argmin(mean_data_window)]\n",
    "    else:\n",
    "        peak_amplitude = np.max(mean_data_window)\n",
    "        peak_latency = diff_wave.times[time_mask][np.argmax(mean_data_window)]\n",
    "    \n",
    "    # Perform sample-by-sample Welch's t-tests\n",
    "    t_values, p_values = stats.ttest_ind(epochs_cond1.get_data(), epochs_cond2.get_data(), \n",
    "                                         axis=0, equal_var=False)\n",
    "    \n",
    "    # Calculate consecutive significant samples\n",
    "    max_consecutive_005 = calculate_consecutive_significant(p_values, 0.05)\n",
    "    max_consecutive_001 = calculate_consecutive_significant(p_values, 0.01)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    mean_diff = diff_wave.data.mean(axis=0)\n",
    "    plt.plot(diff_wave.times, mean_diff * 1e6, 'b-', linewidth=2)  # Convert to microvolts\n",
    "    plt.axvline(peak_latency, color='r', linestyle='--', label=f'Peak Latency: {peak_latency:.3f}s')\n",
    "    plt.axhline(0, color='k', linestyle='-', linewidth=0.5)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Voltage (\\u00b5V)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    \n",
    "    plt.text(0.02, 0.98, f'Peak Amplitude: {peak_amplitude*1e6:.3f} \\u00b5V', transform=plt.gca().transAxes, verticalalignment='top')\n",
    "    plt.text(0.02, 0.93, f'Peak Latency: {peak_latency:.3f}s', transform=plt.gca().transAxes, verticalalignment='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{title.lower().replace(\" \", \"_\")}.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"{title} Results:\")\n",
    "    print(f\"Peak Amplitude: {peak_amplitude*1e6:.3f} \\u00b5V\")\n",
    "    print(f\"Peak Latency: {peak_latency:.3f}s\")\n",
    "    print(f\"Mean of difference wave: {np.mean(mean_diff)*1e6:.3f} \\u00b5V\")\n",
    "    print(f\"Standard deviation of difference wave: {np.std(mean_diff)*1e6:.3f} \\u00b5V\")\n",
    "    print(f\"Min of difference wave: {np.min(mean_diff)*1e6:.3f} \\u00b5V\")\n",
    "    print(f\"Max of difference wave: {np.max(mean_diff)*1e6:.3f} \\u00b5V\")\n",
    "    print(f\"Max consecutive significant samples (p < 0.05): {max_consecutive_005}\")\n",
    "    print(f\"Max consecutive significant samples (p < 0.01): {max_consecutive_001}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot P300b (positive peak)\n",
    "p300b_electrodes = ['C3', 'Cz', 'C4', 'P3', 'Pz', 'P4']\n",
    "p300b_time_window = (0.25, 0.7)\n",
    "calculate_and_plot_difference_wave('LSGD', 'LSGS', p300b_electrodes, p300b_time_window, 'P300b Difference Wave (LSGD - LSGS)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot MMN (negative peak)\n",
    "mmn_electrodes = ['F3', 'Fz', 'F4', 'C3', 'Cz', 'C4']\n",
    "mmn_time_window = (0.1, 0.25)\n",
    "calculate_and_plot_difference_wave('LDGS', 'LSGS', mmn_electrodes, mmn_time_window, 'MMN Difference Wave (LDGS - LSGS)', find_negative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cluster permutation analysis\n",
    "def cluster_permutation_analysis(condition1, condition2, electrodes, time_window, title, n_permutations=1000):\n",
    "    epochs_cond1 = epochs[condition1].copy().pick(electrodes)\n",
    "    epochs_cond2 = epochs[condition2].copy().pick(electrodes)\n",
    "    \n",
    "    # Extract data and create time mask\n",
    "    data1 = epochs_cond1.get_data()\n",
    "    data2 = epochs_cond2.get_data()\n",
    "    times = epochs_cond1.times\n",
    "    time_mask = (times >= time_window[0]) & (times <= time_window[1])\n",
    "    \n",
    "    # Perform cluster permutation test\n",
    "    t_obs, clusters, cluster_pv, H0 = permutation_cluster_test(\n",
    "        [data1[:, :, time_mask], data2[:, :, time_mask]],\n",
    "        n_permutations=n_permutations, threshold=None, tail=0, n_jobs=1, verbose=True)\n",
    "    \n",
    "    # Average t_obs across channels\n",
    "    t_obs_avg = np.mean(t_obs, axis=0)\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i_c, c in enumerate(clusters):\n",
    "        if cluster_pv[i_c] <= 0.05:\n",
    "            c_start, c_stop = c[0][0], c[0][-1] + 1\n",
    "            h = plt.axvspan(times[time_mask][c_start], times[time_mask][c_stop - 1],\n",
    "                            color='r', alpha=0.3)\n",
    "    hf = plt.plot(times[time_mask], t_obs_avg, 'g')\n",
    "    plt.legend((hf[0], h) if 'h' in locals() else (hf[0],), \n",
    "               ('t-values', 'sig. cluster') if 'h' in locals() else ('t-values',))\n",
    "    plt.title(f'{title} Cluster Permutation Test')\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Average t-value\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{title.lower().replace(\" \", \"_\")}_cluster_permutation.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"{title} Cluster Permutation Test Results:\")\n",
    "    print(f\"Number of significant clusters: {sum(cluster_pv <= 0.05)}\")\n",
    "    for i, pvalue in enumerate(cluster_pv):\n",
    "        if pvalue <= 0.05:\n",
    "            c = clusters[i]\n",
    "            c_start, c_stop = c[0][0], c[0][-1] + 1\n",
    "            print(f\"Cluster {i+1}: p-value = {pvalue:.4f}, time range = {times[time_mask][c_start]:.3f} - {times[time_mask][c_stop-1]:.3f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs