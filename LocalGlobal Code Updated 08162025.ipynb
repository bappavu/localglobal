{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "c9d6e66a", "cell_type": "markdown", "source": "# ERP Analysis Workflow\n    \nThis notebook documents the workflow and code used for analyzing ERP data, specifically focusing on P300b and MMN difference waves.", "metadata": {}}, {"id": "7ab5eab8", "cell_type": "markdown", "source": "## Setup and Imports", "metadata": {}}, {"id": "ca445b61", "cell_type": "code", "metadata": {"trusted": false}, "execution_count": null, "source": "import mne\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nfrom mne.stats import permutation_cluster_test\nfrom scipy.ndimage import gaussian_filter1d\nfrom scipy.stats import t", "outputs": []}, {"id": "5d9b9b90", "cell_type": "markdown", "source": "## Load Data", "metadata": {}}, {"id": "b19810a4", "cell_type": "code", "metadata": {"trusted": false}, "execution_count": null, "source": "# Load the epochs\nepochs = mne.read_epochs('42.fif')\nprint(epochs)", "outputs": []}, {"id": "73fe07e8", "cell_type": "markdown", "source": "## Helper Functions", "metadata": {}}, {"id": "63b83e7c", "cell_type": "code", "metadata": {"trusted": false}, "execution_count": null, "source": "def calculate_consecutive_significant(p_values, threshold):\n    sig_mask = p_values < threshold\n    consecutive_count = np.zeros_like(sig_mask, dtype=int)\n    \n    for ch in range(sig_mask.shape[0]):\n        count = 0\n        for t in range(sig_mask.shape[1]):\n            if sig_mask[ch, t]:\n                count += 1\n            else:\n                count = 0\n            consecutive_count[ch, t] = count\n    \n    return np.max(consecutive_count)", "outputs": []}, {"id": "c91dbcd8", "cell_type": "code", "metadata": {"trusted": false}, "execution_count": null, "source": "def calculate_and_plot_difference_wave(conditions1, conditions2, electrodes, time_window, title, find_negative=False):\n    # Combine the epochs for the specified conditions\n    epochs_cond1 = mne.concatenate_epochs([epochs[cond] for cond in conditions1]).pick(electrodes)\n    epochs_cond2 = mne.concatenate_epochs([epochs[cond] for cond in conditions2]).pick(electrodes)\n    \n    evoked_cond1 = epochs_cond1.average()\n    evoked_cond2 = epochs_cond2.average()\n    \n    diff_data = evoked_cond1.data - evoked_cond2.data\n    diff_wave = mne.EvokedArray(diff_data, evoked_cond1.info, tmin=evoked_cond1.times[0])\n    \n    time_mask = (diff_wave.times >= time_window[0]) & (diff_wave.times <= time_window[1])\n    data_window = diff_wave.data[:, time_mask]\n    mean_data_window = data_window.mean(axis=0)\n    \n    if find_negative:\n        peak_amplitude = np.min(mean_data_window)\n        peak_latency = diff_wave.times[time_mask][np.argmin(mean_data_window)]\n    else:\n        peak_amplitude = np.max(mean_data_window)\n        peak_latency = diff_wave.times[time_mask][np.argmax(mean_data_window)]\n    \n    # Perform sample-by-sample Welch's t-tests\n    t_values, p_values = stats.ttest_ind(epochs_cond1.get_data(), epochs_cond2.get_data(), \n                                         axis=0, equal_var=False)\n    \n    # Calculate consecutive significant samples\n    max_consecutive_005 = calculate_consecutive_significant(p_values, 0.05)\n    max_consecutive_001 = calculate_consecutive_significant(p_values, 0.01)\n    \n    # Plot the difference wave\n    plt.figure(figsize=(10, 6))\n    mean_diff = diff_wave.data.mean(axis=0)\n    plt.plot(diff_wave.times, mean_diff * 1e6, 'b-', linewidth=2)  # Convert to microvolts\n    plt.axvline(peak_latency, color='r', linestyle='--', label='Peak Latency: ' + str(round(peak_latency, 3)) + 's')\n    plt.axhline(0, color='k', linestyle='-', linewidth=0.5)\n    plt.title(title)\n    plt.xlabel('Time (s)')\n    plt.ylabel('Voltage (\u00b5V)')\n    plt.legend()\n    plt.grid(True, linestyle=':', alpha=0.6)\n    \n    plt.text(0.02, 0.98, 'Peak Amplitude: ' + str(round(peak_amplitude*1e6, 3)) + ' \u00b5V', \n             transform=plt.gca().transAxes, verticalalignment='top')\n    plt.text(0.02, 0.93, 'Peak Latency: ' + str(round(peak_latency, 3)) + 's', \n             transform=plt.gca().transAxes, verticalalignment='top')\n    \n    plt.tight_layout()\n    plt.savefig(title.lower().replace(\" \", \"_\") + '.png', dpi=300)\n    plt.close()\n    \n    print(title + \" Results:\")\n    print(\"Peak Amplitude: \" + str(round(peak_amplitude*1e6, 3)) + \" \u00b5V\")\n    print(\"Peak Latency: \" + str(round(peak_latency, 3)) + \"s\")\n    print(\"Max consecutive significant samples (p < 0.05): \" + str(max_consecutive_005))\n    print(\"Max consecutive significant samples (p < 0.01): \" + str(max_consecutive_001))", "outputs": []}, {"id": "50855bc7", "cell_type": "markdown", "source": "## MMN Analysis", "metadata": {}}, {"id": "d3d957e9", "cell_type": "code", "metadata": {"trusted": false}, "execution_count": null, "source": "# Calculate and plot MMN (negative peak)\nmmn_electrodes = ['F3', 'Fz', 'F4', 'C3', 'Cz', 'C4']\nmmn_time_window = (0.1, 0.25)\ncalculate_and_plot_difference_wave(['LDGS', 'LDGD'], ['LSGS', 'LSGD'], mmn_electrodes, mmn_time_window, \n                                   'MMN Difference Wave (LDGS + LDGD) vs (LSGS + LSGD)', find_negative=True)", "outputs": []}, {"id": "5dca5c07", "cell_type": "markdown", "source": "## P300b Analysis", "metadata": {}}, {"id": "f2d33b4e", "cell_type": "code", "metadata": {"trusted": false}, "execution_count": null, "source": "# Calculate and plot P300b (positive peak)\np300b_electrodes = ['C3', 'Cz', 'C4', 'P3', 'Pz', 'P4']\np300b_time_window = (0.25, 0.7)\ncalculate_and_plot_difference_wave(['LSGD', 'LDGD'], ['LDGS', 'LSGS'], p300b_electrodes, p300b_time_window, \n                                   'P300b Difference Wave (LSGD + LDGD) vs (LDGS + LSGS)')", "outputs": []}, {"id": "f40a556a", "cell_type": "markdown", "source": "## Cluster Permutation Analysis", "metadata": {}}, {"id": "ba23408e", "cell_type": "code", "metadata": {"trusted": false}, "execution_count": null, "source": "def cluster_permutation_analysis_adjusted(conditions1, conditions2, electrodes, time_window, title, \n                                          n_permutations=10000, alpha=0.05, tail=1):\n    # Combine epochs for each set of conditions\n    epochs_cond1 = mne.concatenate_epochs([epochs[cond] for cond in conditions1]).pick(electrodes)\n    epochs_cond2 = mne.concatenate_epochs([epochs[cond] for cond in conditions2]).pick(electrodes)\n\n    # Extract data and create time mask\n    data1 = epochs_cond1.get_data()\n    data2 = epochs_cond2.get_data()\n    times = epochs_cond1.times\n    time_mask = (times >= time_window[0]) & (times <= time_window[1])\n\n    # Apply time window mask\n    data1 = data1[:, :, time_mask]\n    data2 = data2[:, :, time_mask]\n    times = times[time_mask]\n\n    # Apply Gaussian smoothing\n    data1_smoothed = gaussian_filter1d(data1, sigma=2, axis=2)\n    data2_smoothed = gaussian_filter1d(data2, sigma=2, axis=2)\n\n    # Calculate degrees of freedom and t-threshold\n    n_samples = data1.shape[0] + data2.shape[0]\n    df = n_samples - 2\n\n    if tail == 1:\n        t_threshold = t.ppf(1 - alpha, df)\n    elif tail == -1:\n        t_threshold = -t.ppf(1 - alpha, df)\n    else:\n        raise ValueError(\"Invalid tail parameter. Use 1 for positive or -1 for negative.\")\n\n    print(\"Using t-threshold: \" + str(round(t_threshold, 3)) + \" for alpha=\" + str(alpha) + \n          \", df=\" + str(df) + \", tail=\" + str(tail))\n\n    # Perform cluster permutation test\n    t_obs, clusters, cluster_pv, H0 = permutation_cluster_test(\n        [data1_smoothed, data2_smoothed], n_permutations=n_permutations, threshold=t_threshold, \n        tail=tail, n_jobs=1, verbose=True)\n\n    # Plot results\n    plt.figure(figsize=(10, 6))\n    plt.plot(times, np.mean(t_obs, axis=0), label='Observed t-values')\n    plt.axhline(0, color='k', linestyle='--', linewidth=0.5)\n    plt.title(title)\n    plt.xlabel('Time (s)')\n    plt.ylabel('t-value')\n    plt.grid(True, linestyle=':', alpha=0.6)\n    plt.legend()\n    plt.tight_layout()\n    plt.savefig(title.lower().replace(\" \", \"_\") + '_cluster_permutation.png', dpi=300)\n    plt.close()\n\n    print(\"Cluster Permutation Analysis Results:\")\n    print(\"Number of clusters: \" + str(len(clusters)))\n    print(\"Cluster p-values: \" + str(cluster_pv))", "outputs": []}, {"id": "6f73dbfc", "cell_type": "code", "metadata": {"trusted": false}, "execution_count": null, "source": "# Perform cluster permutation analysis for MMN\ncluster_permutation_analysis_adjusted(['LDGS', 'LDGD'], ['LSGS', 'LSGD'], mmn_electrodes, mmn_time_window, \n                                      'MMN Cluster Permutation Analysis', tail=-1)\n\n# Perform cluster permutation analysis for P300b\ncluster_permutation_analysis_adjusted(['LSGD', 'LDGD'], ['LDGS', 'LSGS'], p300b_electrodes, p300b_time_window, \n                                      'P300b Cluster Permutation Analysis', tail=1)", "outputs": []}]}